name: Weekly NFL Performance Collection

on:
  # Manual trigger for immediate collection
  workflow_dispatch:
    inputs:
      week_number:
        description: 'Week number to collect (1-18)'
        required: false
        type: string
      force_update:
        description: 'Force update existing data'
        required: false
        default: false
        type: boolean
  
  # Automatic weekly collection (Tuesdays at 8 AM UTC - after MNF)
  schedule:
    - cron: '0 8 * * 2'

env:
  PYTHON_VERSION: '3.11'

jobs:
  collect-nfl-data:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Determine collection week
      id: week
      run: |
        if [ -n "${{ github.event.inputs.week_number }}" ]; then
          WEEK="${{ github.event.inputs.week_number }}"
        else
          # Calculate current NFL week (approximate)
          CURRENT_DATE=$(date +%s)
          SEASON_START=$(date -d "2025-09-05" +%s)
          WEEK_DIFF=$(( (CURRENT_DATE - SEASON_START) / 604800 + 1 ))
          WEEK=$(echo $WEEK_DIFF | awk '{print int($1)}')
          WEEK=$(( WEEK > 18 ? 18 : WEEK ))
          WEEK=$(( WEEK < 1 ? 1 : WEEK ))
        fi
        echo "week=$WEEK" >> $GITHUB_OUTPUT
        echo "Collecting data for NFL Week $WEEK"
    
    - name: Check if data already exists
      id: check_data
      run: |
        WEEK="${{ steps.week.outputs.week }}"
        FORCE_UPDATE="${{ github.event.inputs.force_update }}"
        
        if [ -f "data/season_2025_performances.json" ]; then
          HAS_WEEK=$(python -c "
        import json
        try:
            with open('data/season_2025_performances.json', 'r') as f:
                data = json.load(f)
            print('true' if 'week_$WEEK' in data else 'false')
        except:
            print('false')
          ")
          
          if [ "$HAS_WEEK" = "true" ] && [ "$FORCE_UPDATE" != "true" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "Week $WEEK data already exists. Use force_update=true to override."
          else
            echo "skip=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "skip=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Collect NFL performance data
      if: steps.check_data.outputs.skip != 'true'
      env:
        NFL_WEEK: ${{ steps.week.outputs.week }}
      run: |
        echo "=== Collecting NFL Performance Data for Week $NFL_WEEK ==="
        python scripts/collect_nfl_performance.py --week $NFL_WEEK
        
        echo "=== Collection Results ==="
        python -c "
        import json
        with open('data/season_2025_performances.json', 'r') as f:
            data = json.load(f)
        
        week_key = 'week_${{ steps.week.outputs.week }}'
        if week_key in data:
            player_count = len(data[week_key])
            print(f'✅ Successfully collected data for {player_count} players')
            
            # Count players with Sleeper IDs
            mapped_count = sum(1 for p in data[week_key].values() if p.get('sleeper_id'))
            mapping_rate = mapped_count / player_count * 100 if player_count > 0 else 0
            print(f'✅ Sleeper ID mapping: {mapped_count}/{player_count} ({mapping_rate:.1f}%)')
        else:
            print('❌ No data collected')
            exit(1)
        "
    
    - name: Validate data quality
      if: steps.check_data.outputs.skip != 'true'
      run: |
        echo "=== Validating Data Quality ==="
        
        # Check file sizes are reasonable
        PERF_SIZE=$(wc -c < data/season_2025_performances.json)
        TOTALS_SIZE=$(wc -c < data/season_2025_totals.json)
        
        if [ $PERF_SIZE -lt 10000 ]; then
          echo "❌ Performance file too small: $PERF_SIZE bytes"
          exit 1
        fi
        
        if [ $TOTALS_SIZE -lt 1000 ]; then
          echo "❌ Totals file too small: $TOTALS_SIZE bytes"
          exit 1
        fi
        
        echo "✅ File sizes acceptable: Performance=$PERF_SIZE, Totals=$TOTALS_SIZE"
        
        # Validate JSON structure
        python -c "
        import json
        
        # Test performance data
        with open('data/season_2025_performances.json', 'r') as f:
            perf_data = json.load(f)
        
        week_key = 'week_${{ steps.week.outputs.week }}'
        if week_key not in perf_data:
            raise Exception(f'Week key {week_key} not found')
        
        week_data = perf_data[week_key]
        if len(week_data) == 0:
            raise Exception('No players in week data')
        
        # Test sample player structure
        sample_player = list(week_data.values())[0]
        required_fields = ['player_name', 'position', 'stats', 'sleeper_id']
        for field in required_fields:
            if field not in sample_player:
                raise Exception(f'Missing field: {field}')
        
        # Test totals data
        with open('data/season_2025_totals.json', 'r') as f:
            totals_data = json.load(f)
        
        if len(totals_data) == 0:
            raise Exception('No players in totals data')
        
        print('✅ Data structure validation passed')
        "
    
    - name: Commit updated data
      if: steps.check_data.outputs.skip != 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add the updated files
        git add data/season_2025_performances.json
        git add data/season_2025_totals.json
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Update NFL performance data for Week ${{ steps.week.outputs.week }}
          
          - Collected data for ${{ steps.week.outputs.week }} players
          - Updated season totals
          - Automated collection on $(date)"
          
          git push
          echo "✅ Data committed and pushed to repository"
        fi
    
    - name: Generate collection summary
      if: always()
      run: |
        echo "=== Collection Summary ==="
        echo "Week: ${{ steps.week.outputs.week }}"
        echo "Status: ${{ steps.check_data.outputs.skip == 'true' && 'Skipped (data exists)' || 'Completed' }}"
        echo "Timestamp: $(date)"
        
        if [ "${{ steps.check_data.outputs.skip }}" != "true" ]; then
          if [ -f "data/season_2025_performances.json" ]; then
            python -c "
        import json
        with open('data/season_2025_performances.json', 'r') as f:
            data = json.load(f)
        
        weeks = [k for k in data.keys() if k.startswith('week_')]
        total_performances = sum(len(data[k]) for k in weeks)
        
        print(f'Total weeks collected: {len(weeks)}')
        print(f'Total player performances: {total_performances}')
            "
          fi
        fi
    
    - name: Upload artifacts on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: failed-collection-week-${{ steps.week.outputs.week }}
        path: |
          data/
          scripts/collect_nfl_performance.py
        retention-days: 7
